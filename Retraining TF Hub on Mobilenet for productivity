{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Retraining TF Hub on Mobilenet for productivity","provenance":[{"file_id":"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb","timestamp":1596495197072}],"private_outputs":true,"collapsed_sections":["ScitaPqhKtuW"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ScitaPqhKtuW"},"source":["##### Copyright 2019 The TensorFlow Hub Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jvztxQ6VsK2k","colab":{}},"source":["# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oYM61xrTsP5d"},"source":["# Retraining an Image Classifier\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MfBg1C5NB3X0"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf2_image_retraining\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tf2_image_retraining.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"L1otmJgmbahf"},"source":["## Introduction\n","\n","Image classification models have millions of parameters. Training them from\n","scratch requires a lot of labeled training data and a lot of computing power. Transfer learning is a technique that shortcuts much of this by taking a piece of a model that has already been trained on a related task and reusing it in a new model.\n","\n","This Colab demonstrates how to build a Keras model for classifying five species of flowers by using a pre-trained TF2 SavedModel from TensorFlow Hub for image feature extraction, trained on the much larger and more general ImageNet dataset. Optionally, the feature extractor can be trained (\"fine-tuned\") alongside the newly added classifier.\n","\n","### Looking for a tool instead?\n","\n","This is a TensorFlow coding tutorial. If you want a tool that just builds the TensorFlow or TF Lite model for, take a look at the [make_image_classifier](https://github.com/tensorflow/hub/tree/master/tensorflow_hub/tools/make_image_classifier) command-line tool that gets [installed](https://www.tensorflow.org/hub/installation) by the PIP package `tensorflow-hub[make_image_classifier]`, or at [this](https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/image_classification.ipynb) TF Lite colab.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bL54LWCHt5q5"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dlauq-4FWGZM","colab":{}},"source":["import itertools\n","import os\n","\n","import matplotlib.pylab as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","print(\"TF version:\", tf.__version__)\n","print(\"Hub version:\", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mmaHHH7Pvmth"},"source":["## Select the TF2 SavedModel module to use\n","\n","For starters, use https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4. The same URL can be used in code to identify the SavedModel and in your browser to show its documentation. (Note that models in TF1 Hub format won't work here.)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FlsEcKVeuCnf","colab":{}},"source":["module_selection = (\"mobilenet_v2_100_224\", 224) #@param [\"(\\\"mobilenet_v2_100_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n","handle_base, pixels = module_selection\n","MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n","\n","BATCH_SIZE = 32 #@param {type:\"integer\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUBC01ZHiI95","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yTY8qzyYv3vl"},"source":["## Set up the project dataset\n","\n","Inputs are suitably resized for the selected module. Dataset augmentation (i.e., random distortions of an image each time it is read) improves training, esp. when fine-tuning."]},{"cell_type":"code","metadata":{"id":"9aNE-tLOic6A","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/drive/My Drive/candidates/\")\n","data_dir = \"0.2\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WBtFK1hO8KsO","colab":{}},"source":["#data_dir = tf.keras.utils.get_file(\n","    #'flower_photos',\n","    #'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n","    #untar=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"umB5tswsfTEQ","colab":{}},"source":["datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n","dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n","                   interpolation=\"bilinear\")\n","\n","valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    **datagen_kwargs)\n","valid_generator = valid_datagen.flow_from_directory(\n","    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n","\n","do_data_augmentation = False #@param {type:\"boolean\"}\n","if do_data_augmentation:\n","  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","      rotation_range=40,\n","      horizontal_flip=True,\n","      width_shift_range=0.2, height_shift_range=0.2,\n","      shear_range=0.2, zoom_range=0.2,\n","      **datagen_kwargs)\n","else:\n","  train_datagen = valid_datagen\n","train_generator = train_datagen.flow_from_directory(\n","    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FS_gVStowW3G"},"source":["## Defining the model\n","\n","All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n","\n","For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RaJW3XrPyFiF","colab":{}},"source":["do_fine_tuning = False #@param {type:\"boolean\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"50FYNIb1dmJH","colab":{}},"source":["print(\"Building model with\", MODULE_HANDLE)\n","model = tf.keras.Sequential([\n","    # Explicitly define the input shape so the model can be properly\n","    # loaded by the TFLiteConverter\n","    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n","    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n","    tf.keras.layers.Dropout(rate=0.2),\n","    tf.keras.layers.Dense(train_generator.num_classes,\n","                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n","])\n","model.build((None,)+IMAGE_SIZE+(3,))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u2e5WupIw2N2"},"source":["## Training the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9f3yBUvkd_VJ","colab":{}},"source":["model.compile(\n","  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n","  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n","  metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w_YKX2Qnfg6x","colab":{}},"source":["steps_per_epoch = train_generator.samples // train_generator.batch_size\n","validation_steps = valid_generator.samples // valid_generator.batch_size\n","hist = model.fit(\n","    train_generator,\n","    epochs=5, steps_per_epoch=steps_per_epoch,\n","    validation_data=valid_generator,\n","    validation_steps=validation_steps).history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CYOw0fTO1W4x","colab":{}},"source":["plt.figure()\n","plt.ylabel(\"Loss (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,2])\n","plt.plot(hist[\"loss\"])\n","plt.plot(hist[\"val_loss\"])\n","\n","plt.figure()\n","plt.ylabel(\"Accuracy (training and validation)\")\n","plt.xlabel(\"Training Steps\")\n","plt.ylim([0,1])\n","plt.plot(hist[\"accuracy\"])\n","plt.plot(hist[\"val_accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YCsAsQM1IRvA"},"source":["Finally, the trained model can be saved for deployment to TF Serving or TF Lite (on mobile) as follows."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LGvTi69oIc2d","colab":{}},"source":["saved_model_path = \"/content/drive/My Drive/candidates/saved_productivity_model\"\n","tf.saved_model.save(model, saved_model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gw3lthAnwrF4","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XW5BwVTTTY2","colab_type":"code","colab":{}},"source":["!pip install tensorflowjs "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTS22mrhUDtO","colab_type":"code","colab":{}},"source":["import tensorflowjs\n","!tensorflowjs_converter \\\n","    --input_format=tf_saved_model \\\n","    --output_node_names='pred_y' \\\n","    --saved_model_tags=serve \\\n","    [/content/drive/My Drive/candidates/saved_productivity_model] [/content/drive/My Drive/candidates/web_model]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBU32wvXUXFo","colab_type":"code","colab":{}},"source":["imported = tf.saved_model.load(saved_model_path)\n","assert imported(tf.constant(3.)).numpy() == 3\n","imported.mutate(tf.constant(2.))\n","assert imported(tf.constant(3.)).numpy() == 6"],"execution_count":null,"outputs":[]}]}